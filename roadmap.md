# The Basics

## Python 

- Sequences
  - sets
    - Removing duplicates
    - disjunction
    - Conjunction
  - Slicing
  - Dictionary: and, or
    - Counter
  - Comprehensions
    - List
    - Set
    - Dictionary
- Tenary
- Printing
  - Secrets of print (sep,end), flush
  - Fstring
  - superprint (from the parent)
- Swap in place
- Start-up (__name__ == “__main__”)
- Exception handling
- Args & Kwargs
- lambda (closures)
- toto: compelte this from ase24/docs/ninjas

## Just enough statistics

- [entropy](entropy.md)
- standard deviation
  - incremental
  - non-parametric
- stats
  - effect size
  - significance
  - ranking (SK)

## Shell

- Regex
- awk
- Makefile

# Smarter Scripting
- little languages (regx, data models headers, __d__2options)
- DRY, not WET
- licensing
- packaging
- information hiding
  - API https://www.hyrumslaw.com/ (you get one chance to write an API)

## scripting

- script101
    - documentation
  - exposed control parameters
  - test suite
  - piping
    - shut the heck up (quiet execution)
    - standard files STDIN, STDERR, STROUT
  - seed control
- automate everything (makefile: insert awkward stuff there)
- test engine
  - setup,
    - reset
  - tear down
  - $?
- documentation (docstrings)
  - tuning
- decomposition (pipes, stdio)
- less is more (technical debt, my DATA model)
- precommit hooks
  - e.g. badging

# Easier AI

- active learning (one thing per leaf)
Data

classifier
- Naive bayes
- knn (no clustering) <== can be regressions as well
- decision tree

clustering
- one sample per leaf (tiny training)
- regression and classifiication
- sample plus propergate

- lessons:
  - data reduction (just one sample per leaf)
  - when recursively clustering, use less and less to find poles.

#KE
W1: data.
  -   Little languages: data headers (bigger: regular expressions)
- Test suite
- documentation
- Pipe and filter/ architecture

W2: classification
- Bayes, 
- Labelling

# Read More
